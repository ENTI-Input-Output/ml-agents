{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Output. Delivery One\n",
    "\n",
    "<img src=\"../docs/images/image-banner.png\" align=\"middle\" width=\"3000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G01: Victor Armisen and David Recuenco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "The purpose of this notebook is explaining our work with the environment \"Tennis\" from the ml-agents examples.\n",
    "This example, as its name says, simulates a tennis match between two agents which follows the real tennis rules.\n",
    "What we wanted to do with the example was using only an agent and:\n",
    "* Make the agent play paddle alone and following the game's rules: the ball has to touch the ground once before being hit and if the ball touches the ground two times in a row without touching the front wall, the point is lost.\n",
    "* Make the agent do keepy-ups not letting the ball touching the ground. \n",
    "* The same keepy-ups as above but with wind, making it harder for the agent to keep the ball in the air."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The team\n",
    "Name | Enti email | Picture\n",
    "--- | --- | ---\n",
    "Victor Armisen | victorarmisencapo@enti.cat | placeholder picture\n",
    "David Recuenco | davidrecuencooliver@enti.cat | <img src=\"../docs/images/DRO.png\" width=\"100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Case Analysis\n",
    "The example is managed by 3 scripts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **TennisArea**\n",
    "\n",
    "Manages the ball's physics and has the function to reset the match, spawning the ball in a random side of the court."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    public void MatchReset()\n",
    "    {\n",
    "        var ballOut = Random.Range(6f, 8f);\n",
    "        var flip = Random.Range(0, 2);\n",
    "        if (flip == 0)\n",
    "        {\n",
    "            ball.transform.position = new Vector3(-ballOut, 6f, 0f) + transform.position;\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            ball.transform.position = new Vector3(ballOut, 6f, 0f) + transform.position;\n",
    "        }\n",
    "        m_BallRb.velocity = new Vector3(0f, 0f, 0f);\n",
    "        ball.transform.localScale = new Vector3(.5f, .5f, .5f);\n",
    "        ball.GetComponent<HitWall>().lastAgentHit = -1;\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **TennisAgent**\n",
    "\n",
    "Obviously, manages the agent which in this case is the racket. The script has the heuristic, movement and reset.\n",
    "In the agent we slightly change its properties in the case of Keep Up to simulate the touches.\n",
    "In all cases, we use the inputs of the vectorActions to change the speeds and rotations of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Add some code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **HitWall**\n",
    "\n",
    "We check the collisions of the ball with the objects in the environment and give the corresponding rewards according to these events.\n",
    "## CAMBIAR ESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            else if (collision.gameObject.name == \"wallB\")\n",
    "            {\n",
    "                // Agent B hits into wall or agent A hit a winner\n",
    "                if (lastAgentHit == 1 || lastFloorHit == FloorHit.FloorBHit)\n",
    "                {\n",
    "                    AgentAWins();\n",
    "                }\n",
    "                // Agent A hits long\n",
    "                else\n",
    "                {\n",
    "                    AgentBWins();\n",
    "                }\n",
    "            }\n",
    "            else if (collision.gameObject.name == \"floorA\")\n",
    "            {\n",
    "                // Agent A hits into floor, double bounce or service\n",
    "                if (lastAgentHit == 0 || lastFloorHit == FloorHit.FloorAHit || lastFloorHit == FloorHit.Service)\n",
    "                {\n",
    "                    AgentBWins();\n",
    "                }\n",
    "                else\n",
    "                {\n",
    "                    lastFloorHit = FloorHit.FloorAHit;\n",
    "                    //successful serve\n",
    "                    if (!net)\n",
    "                    {\n",
    "                        net = true;\n",
    "                    }\n",
    "                }\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewards:\n",
    "We give positive rewards in relation if the ball touches it simply touches the racket. According to distances and time.\n",
    "We give negative rewards if the ball hits the ground and if it hits invisible walls that represent that it goes off the court.\n",
    "## CAMBIAR ESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    void AgentAWins()\n",
    "    {\n",
    "        m_AgentA.SetReward(1);\n",
    "        m_AgentB.SetReward(-1);\n",
    "        m_AgentA.score += 1;\n",
    "        Reset();\n",
    "\n",
    "    }\n",
    "\n",
    "    void AgentBWins()\n",
    "    {\n",
    "        m_AgentA.SetReward(-1);\n",
    "        m_AgentB.SetReward(1);\n",
    "        m_AgentB.score += 1;\n",
    "        Reset();\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States:\n",
    "We use States to check more specific events and thus achieve better results.\n",
    "For example, to check if the ball bounces on the ground, if it hits the wall on the ground ...\n",
    "## CAMBIAR ESTO Y EXPLICAR DEL EJEMPLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    public enum FloorHit\n",
    "        {\n",
    "            Service,\n",
    "            FloorHitUnset,\n",
    "            FloorAHit,\n",
    "            FloorBHit\n",
    "        }\n",
    "\n",
    "    public FloorHit lastFloorHit;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training:\n",
    "We do learning checks around a 100K Steps. From then on, we consider that, if we see correct results, the model is worth it.\n",
    "We check these results through the variables used and the graphs that we obtain locally with Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis\n",
    "Explicaci√≥n\n",
    "\n",
    "Add pictures here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New case proposal\n",
    "\n",
    "As mentioned in the introduction, we have three different cases to train the agent with.\n",
    "For making this possible we had to remove one of the scene's agents and adapt the scripts to one agent only since they were made for two.\n",
    "\n",
    "The spawn of the ball had to be modified since it was randomly spawned to both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        var ballOut = Random.Range(-6f, -8f); // distancia en x\n",
    "        ball.transform.position = new Vector3(ballOut, 8f, 0f) + transform.position;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paddle:\n",
    "\n",
    "<img src=\"../docs/images/Paddle.png\" align=\"middle\"/>\n",
    "\n",
    "For the Paddle case all was focused on the collisions the ball made. For this, an enum was used as for a status machine in order to check what it colided with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    void OnCollisionEnter(Collision collision) {\n",
    "        switch (state) {\n",
    "            case Status.Floor:\n",
    "                if (collision.gameObject.name == \"Agent\") {\n",
    "                    state = Status.Agent;\n",
    "                } \n",
    "                else Death();\n",
    "                break;\n",
    "\n",
    "            case Status.Agent:\n",
    "                if (collision.gameObject.name == \"WallFront\") {\n",
    "                    if (!firstGame) {\n",
    "                        currentTouches++;\n",
    "                        GivePositiveReward();\n",
    "                    }\n",
    "                    else {\n",
    "                        firstGame = false;\n",
    "                        GivePositiveReward_Less();\n",
    "                    }\n",
    "                    state = Status.Wall;\n",
    "                }\n",
    "                else Death();\n",
    "                break;\n",
    "\n",
    "            case Status.Wall:\n",
    "                if (collision.gameObject.name == \"Floor\") state = Status.Floor;\n",
    "                else Death();\n",
    "                break;\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of reward given to the agent:\n",
    "* **GivePositiveReward()** Gives a reward of value 1. Used for the normal touches.\n",
    "* **GivePositiveReward_Less()** Gives a reward of value 0.5. Used for the first successful touch since the next ones are the ones that count.\n",
    "\n",
    "As for the results, the agent's learning is slow at first but as it's swon in the graphs, it learns exponentially\n",
    "<img src=\"../docs/images/Paddle_ELO.png\" align=\"middle\"/>\n",
    "<img src=\"../docs/images/Paddle_AR.png\" align=\"middle\"/>\n",
    "<img src=\"../docs/images/Paddle_EL.png\" align=\"middle\"/>\n",
    "\n",
    "One trick used to help out the agent to learn faster got nothing to do with the rewards: I changed the height position of the spawn of the ball so the agent does not need to wait for the ball to fall. The ball spawns close to the agent so he can hit the ball and let it enough space to hit the wall and then the floor without letting the agent hit the ball in the middle that easily. Another trick used to help out the agent was keeping the rewards constant to it gets used to the training without changes while learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keepy-ups\n",
    "<img src=\"../docs/images/KeepsUps.png\" align=\"middle\"/>\n",
    "In the first case of Keepy-ups, we have a first case without rotation in which the racket has to learn to approach the instanced ball in a random way and keep the touches up.\n",
    "In the second case, the racket has to learn to control the rotation of the racket and we send the ball to different places already in XYZ. When instantiating the ball, we apply a force to it so that it does not simply fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Code Keepy-ups\n",
    "//EX3: Wind and Rotation\n",
    "Vector3 dir = ball.transform.position - transform.position;\n",
    "dir.Normalize();\n",
    "\n",
    "distance = ball.transform.position.x - transform.position.x;\n",
     "distance = Mathf.Abs(distance);\n",
     "if (distance < 2.0f)\n",
     "{\n",
         "AddReward(1);\n",
     "}\n",
     "else\n",
     "{\n",
         "AddReward(-1);\n",
     "}\n",
    "m_AgentRb.velocity = new Vector3(moveX * dir.x * 30.0f, m_AgentRb.velocity.y, 0f);\n",
    "\n",
    "//EX3: Wind and Rotation\n",
    "m_AgentRb.velocity = new Vector3(moveX * dir.x * magnitude, m_AgentRb.velocity.y, moveX * dir.z * magnitude);\n",
            "m_AgentRb.transform.rotation = Quaternion.Euler(-180f, -180f, 55f * rotate);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keepy-ups with wind\n",
    "<img src=\"../docs/images/EX3_Tennis_ELO.png\" align=\"middle\"/>\n",
    "<img src=\"../docs/images/EX3_Tennis_E.png\" align=\"middle\"/>\n",
    "<img src=\"../docs/images/EX3_Tennis_C.png\" align=\"middle\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// code del wind I guess"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
