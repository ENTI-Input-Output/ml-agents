{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G06 - Wall Jump\n",
    "---\n",
    "\n",
    "## Index\n",
    "[1.Introduction](#intro) <br>\n",
    "[2.Case analysis](#oldCase) <br>\n",
    "[3.Performance analysis](#performance) <br>\n",
    "[4.New case proposal](#newCase) <br>\n",
    "[5.Team](#team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"intro\"></a>1. Introduction\n",
    "This notebook has all the information related to <b>G06</b>'s delivery 1. Here you can find an analysis of the <b>Wall Jump</b> example of Unity's ml-agents, as well as a new case proposal of the same example, with all information needed to reproduce it by yourself.\n",
    "\n",
    "This notebook also works as a post mortem for our new proposal's implementation.\n",
    "\n",
    "|![AlexRivero](g06-img/Alex.png)|![AlexRivero](g06-img/Alex.png)|\n",
    "|---|---|\n",
    "|Alex Rivero Ferràs|David Recuero Redrado|\n",
    "|alexriveroferras@enti.cat|davidrecueroredrado@enti.cat|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"oldCase\"></a>2. Case analysis\n",
    "\n",
    "### Rewards\n",
    "In this example there are 3 rewards given to the agent depending on its performance solving the problem:\n",
    "- <span style=\"color:green\">+1.0, if the agent reaches the goal</span> - Given to the agent in the <i>OnTriggerStay()</i> (using the collider of the goal)\n",
    "- <span style=\"color:red\">-0.0005, for every step the agent does</span> - Given to the agent in <i>MoveAgent()</i>. This reward motivates the agent to find the optimal path to the goal (using as less movements as possible)\n",
    "- <span style=\"color:red\">-1.0, if the agent or the cube falls off the platform</span> - Given to the agent in <i>AgentAction()</i>\n",
    "![MoveAgent](g06-img/Rewards.png)\n",
    "\n",
    "### Actions\n",
    "The agent can take 4 different main actions, each of them with multiple options:\n",
    "<img style=\"float: right;\" src=\"g06-img/Movement.gif\">\n",
    "- Forward movement\n",
    "    - Forward\n",
    "    - Backwards \n",
    "    - No action\n",
    "- Side movement\n",
    "    - Left\n",
    "    - Right\n",
    "    - No action\n",
    "- Rotation\n",
    "    - Left\n",
    "    - Right\n",
    "    - No action\n",
    "- Jump\n",
    "    - Jump\n",
    "    - No action\n",
    "    \n",
    "### Observations\n",
    "The agent has 2 different observations in the <i>CollectObservations()</i> function: the position of the agent and a boolean indicating if the agent is grounded (as the agent only receives the reward if it stays on the goal being grounded). It also has 14 ray casts each detecting 4 possible objects.\n",
    "\n",
    "### How it all works\n",
    "In this example the agent has to reach a green area tagged as \"goal\". The environment has 3 different states:\n",
    "- The goal accessible for the agent <b>without any wall</b> blocking it.\n",
    "- A <b>small-sized wall</b> blocking the way to the goal. In this case the agent can jump over the wall with a simple jump.\n",
    "- A <b>big-sized wall</b> blocking the way to the goal. In this case the agent has to push a cube against the wall, jump on the cube and then jump over the wall.\n",
    "\n",
    "As this example has 3 different states it would take too long to train it using the \"hard way\" (trying randomly every situation). That's why it uses curriculum learning.<br>\n",
    "Curriculum learning uses progression to train the agent. In this example, the wall scales up when the agent reaches a threshold. The agent learns to solve the 3 states progressively, making it easier and faster to train.\n",
    "\n",
    "To do so, the agent uses 2 brains and, depending on the current case, the brain is passed to the behavior parameters using the <i>ConfigureAgent()</i> function.\n",
    "\n",
    "```c#\n",
    "void ConfigureAgent(int config)\n",
    "    {\n",
    "        var localScale = wall.transform.localScale;\n",
    "        if (config == 0)\n",
    "        {\n",
    "            localScale = new Vector3(\n",
    "                localScale.x,\n",
    "                Academy.Instance.FloatProperties.GetPropertyWithDefault(\"no_wall_height\", 0),\n",
    "                localScale.z);\n",
    "            wall.transform.localScale = localScale;\n",
    "            GiveModel(\"SmallWallJump\", noWallBrain);\n",
    "        }\n",
    "        else if (config == 1)\n",
    "        {\n",
    "            localScale = new Vector3(\n",
    "                localScale.x,\n",
    "                Academy.Instance.FloatProperties.GetPropertyWithDefault(\"small_wall_height\", 4),\n",
    "                localScale.z);\n",
    "            wall.transform.localScale = localScale;\n",
    "            GiveModel(\"SmallWallJump\", smallWallBrain);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            var min = Academy.Instance.FloatProperties.GetPropertyWithDefault(\"big_wall_min_height\", 8);\n",
    "            var max = Academy.Instance.FloatProperties.GetPropertyWithDefault(\"big_wall_max_height\", 8);\n",
    "            var height = min + Random.value * (max - min);\n",
    "            localScale = new Vector3(\n",
    "                localScale.x,\n",
    "                height,\n",
    "                localScale.z);\n",
    "            wall.transform.localScale = localScale;\n",
    "            GiveModel(\"BigWallJump\", bigWallBrain);\n",
    "        }\n",
    "    }\n",
    "```\n",
    "\n",
    "The <i>SmallWallJump</i> brain is used both for when there's no wall and when the wall is low enough to jump over it. The <i>BigWallJump</i> brain is used when the wall is too high and the agent needs the cube to jump over it.\n",
    "\n",
    "Here's a link to the repository's docs where curriculum learning is explained: https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Training-Curriculum-Learning.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"performance\"></a>3. Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"newCase\"></a>4. New case proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"team\"></a>5. Team\n",
    "\n",
    "|![AlexRivero](g06-img/Alex.png)|![AlexRivero](g06-img/Alex.png)|\n",
    "|---|---|\n",
    "|Alex Rivero Ferràs|David Recuero Redrado|\n",
    "|alexriveroferras@enti.cat|davidrecueroredrado@enti.cat|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
