{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML-Agents Toolkit - G02 Push Block\n",
    "## Environment Basics\n",
    "\n",
    "### 1. Introduction\n",
    "This notebook contains a walkthrough of the evolution of the Push Block environment, which we have modified in order to make it complete more dificult tasks. The team is displayed on the 5th section of the notebook.\n",
    "\n",
    "\n",
    "### 2. Case Analysis\n",
    "![Push Block](img/40.png)\n",
    "Push Block is comprised by an agend within a room, a goal and a block that the agent has to puh toward the goal. The agent gets the following rewards\n",
    "- For each step taken, 1/maxSteps points are subtracted\n",
    "- When the block is placed in the goal, 5 points are added\n",
    "\n",
    "The diferent states of the agent are:\n",
    "- Exploring\n",
    "- Heading to block\n",
    "- Pushing block\n",
    "\n",
    "Those states are shared by every case explained in this notebook\n",
    "\n",
    "The diferent states of the scene are:\n",
    "- Zero blocks scored\n",
    "- One block scored\n",
    "\n",
    "Whenever the agent places the block in the goal, the scene resets and the block spawns in a random position.\n",
    "\n",
    "\n",
    "### 3. Performance Analysis\n",
    "\n",
    "### 4. New Case Proposal\n",
    "#### 4.1 2 Blocks\n",
    "![2 blocks](img/41.png)\n",
    "Instead of only one block, in this example we add a second block, which we have to place in the same goal. The agent gets the following rewards\n",
    "- Like in the prior example, the agent loses 1/maxSteps points for each step taken.\n",
    "- When the agent scores the first goal, the agent is given 1 point.\n",
    "- When the agent scores the second goal, the agent is given 5 points.\n",
    "\n",
    "The diferent states of the scene are:\n",
    "- Zero blocks scored\n",
    "- One block scored\n",
    "- Two blocks scored\n",
    "\n",
    "Whenever the agent places a block is placed on the goal, placing the same block again doesn't give any more points. Alseo, when  the agent places both blocks in the goal, the scene resets and both blocks spawn in a random position.\n",
    "\n",
    "#### 4.2 Touch Blocks\n",
    "![Touch blocks](img/42.png)\n",
    "The scene is comprised by two blocks and single goals. The agent has to place each both blocks in the same goals, but while touching each other. The agent gets the following rewards\n",
    "- Like in the prior examples, the agent loses 1/maxSteps points for each step taken.\n",
    "- If the two blocks have touched each other:\n",
    "    - If one block touches the goal, the score is set to 0.5\n",
    "    - If both blocks touch the goal, the score is set to \n",
    "- If the two blocks haven't touched each other:\n",
    "    - If one block touches the goal, the score is set to 0.75\n",
    "    - If both blocks touch the goal, the score is set to 1\n",
    "\n",
    "The diferent states of the scene are:\n",
    "- Zero blocks scored\n",
    "- One block scored\n",
    "- Two blocks scored\n",
    "\n",
    "Whenever the agent places a block is placed on the goal, placing the same block again doesn't give any more points. Alseo, when both blocks in the goal, the scene resets and both blocks spawn in a random position.\n",
    "\n",
    "#### 4.3 Separated Blocks\n",
    "![Separated blocks](img/43.png)\n",
    "The scene is comprised by two blocks and two goals, a purple one and a green one. The agent has to place each block in its correspondent goal. The agent gets the following rewards\n",
    "\n",
    "- Like in the prior examples, the agent loses 1/maxSteps points for each step taken.\n",
    "- When he places the first block, his total reward is set to 0.5\n",
    "- When he places the second block, his total reward is set to 1\n",
    "\n",
    "The diferent states of the scene are:\n",
    "- Zero blocks scored\n",
    "- One block scored\n",
    "- Two blocks scored\n",
    "\n",
    "Whenever the agent places a block is placed on the goal, placing the same block again doesn't give any more points. Alseo, when  the agent places both blocks in the goal, the scene resets and both blocks spawn in a random position.\n",
    "\n",
    "### 5. Team\n",
    "\n",
    "| Name  | Surnames        | Email                        | Picture |\n",
    "| ----  | --------------- | ---------------------------- | ------- |\n",
    "| Roger | Sala Majà       | rogersalamaja@enti.cat       | ![Roger](img/Roger.png) |\n",
    "| Òscar | Masferrer Rubio | oscarmasferrerrubio@enti.cat | ![Òscar](img/Oscar.png) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20256), started 0:01:02 ago. (Use '!kill 20256' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-34cc64bb51505ea1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-34cc64bb51505ea1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
